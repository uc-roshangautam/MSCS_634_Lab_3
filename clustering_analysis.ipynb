{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c9d2c8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "class SimpleKMedoids:\n",
    "    def __init__(self, n_clusters=3, max_iter=100, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit_predict(self, X):\n",
    "        np.random.seed(self.random_state)\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize medoids randomly\n",
    "        medoid_indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "        self.medoid_indices_ = medoid_indices.copy()\n",
    "        \n",
    "        for iteration in range(self.max_iter):\n",
    "            # Assign points to nearest medoids\n",
    "            distances = euclidean_distances(X, X[medoid_indices])\n",
    "            labels = np.argmin(distances, axis=1)\n",
    "            \n",
    "            # Update medoids\n",
    "            new_medoid_indices = []\n",
    "            total_cost = 0\n",
    "            \n",
    "            for k in range(self.n_clusters):\n",
    "                cluster_mask = labels == k\n",
    "                if np.sum(cluster_mask) == 0:\n",
    "                    new_medoid_indices.append(medoid_indices[k])\n",
    "                    continue\n",
    "                    \n",
    "                cluster_points = X[cluster_mask]\n",
    "                cluster_indices = np.where(cluster_mask)[0]\n",
    "                \n",
    "                # Find the point that minimizes total distance to other points in cluster\n",
    "                min_cost = float('inf')\n",
    "                best_medoid = medoid_indices[k]\n",
    "                \n",
    "                for i, point_idx in enumerate(cluster_indices):\n",
    "                    cost = np.sum(euclidean_distances([X[point_idx]], cluster_points))\n",
    "                    if cost < min_cost:\n",
    "                        min_cost = cost\n",
    "                        best_medoid = point_idx\n",
    "                \n",
    "                new_medoid_indices.append(best_medoid)\n",
    "                total_cost += min_cost\n",
    "            \n",
    "            new_medoid_indices = np.array(new_medoid_indices)\n",
    "            \n",
    "            # Check for convergence\n",
    "            if np.array_equal(sorted(medoid_indices), sorted(new_medoid_indices)):\n",
    "                break\n",
    "                \n",
    "            medoid_indices = new_medoid_indices\n",
    "            \n",
    "        self.medoid_indices_ = medoid_indices\n",
    "        self.inertia_ = total_cost\n",
    "        \n",
    "        # Final assignment\n",
    "        distances = euclidean_distances(X, X[medoid_indices])\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "        \n",
    "        return labels\n",
    "\n",
    "# Load and prepare the dataset\n",
    "wine_data = load_wine()\n",
    "X = wine_data.data\n",
    "y = wine_data.target\n",
    "feature_names = wine_data.feature_names\n",
    "\n",
    "print(\"Dataset Shape:\", X.shape)\n",
    "print(\"Number of classes:\", len(np.unique(y)))\n",
    "print(\"Class distribution:\", np.bincount(y))\n",
    "print(\"\\nFeature names:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"{i+1}. {name}\")\n",
    "\n",
    "# Standardize the dataset using z-score normalization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\nData standardized successfully\")\n",
    "print(\"Mean after scaling:\", np.mean(X_scaled, axis=0)[:5])\n",
    "print(\"Std after scaling:\", np.std(X_scaled, axis=0)[:5])\n",
    "\n",
    "# Implement K-Means Clustering\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"K-MEANS CLUSTERING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "kmeans_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Calculate performance metrics for K-Means\n",
    "kmeans_silhouette = silhouette_score(X_scaled, kmeans_labels)\n",
    "kmeans_ari = adjusted_rand_score(y, kmeans_labels)\n",
    "\n",
    "print(f\"K-Means Silhouette Score: {kmeans_silhouette:.4f}\")\n",
    "print(f\"K-Means Adjusted Rand Index: {kmeans_ari:.4f}\")\n",
    "\n",
    "# Implement K-Medoids Clustering\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"K-MEDOIDS CLUSTERING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "kmedoids = SimpleKMedoids(n_clusters=3, random_state=42)\n",
    "kmedoids_labels = kmedoids.fit_predict(X_scaled)\n",
    "\n",
    "# Calculate performance metrics for K-Medoids\n",
    "kmedoids_silhouette = silhouette_score(X_scaled, kmedoids_labels)\n",
    "kmedoids_ari = adjusted_rand_score(y, kmedoids_labels)\n",
    "\n",
    "print(f\"K-Medoids Silhouette Score: {kmedoids_silhouette:.4f}\")\n",
    "print(f\"K-Medoids Adjusted Rand Index: {kmedoids_ari:.4f}\")\n",
    "\n",
    "# Performance comparison\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Metric':<25} {'K-Means':<15} {'K-Medoids':<15}\")\n",
    "print(\"-\" * 55)\n",
    "print(f\"{'Silhouette Score':<25} {kmeans_silhouette:<15.4f} {kmedoids_silhouette:<15.4f}\")\n",
    "print(f\"{'Adjusted Rand Index':<25} {kmeans_ari:<15.4f} {kmedoids_ari:<15.4f}\")\n",
    "\n",
    "# Use PCA for visualization (reduce to 2D)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"\\nPCA explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_):.4f}\")\n",
    "\n",
    "# Create visualizations\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Original classes\n",
    "scatter1 = ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
    "ax1.set_title('Original Wine Classes')\n",
    "ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.3f})')\n",
    "ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.3f})')\n",
    "plt.colorbar(scatter1, ax=ax1)\n",
    "\n",
    "# K-Means results\n",
    "scatter2 = ax2.scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.7)\n",
    "# Plot centroids (transform back to PCA space)\n",
    "centroids_pca = pca.transform(kmeans.cluster_centers_)\n",
    "ax2.scatter(centroids_pca[:, 0], centroids_pca[:, 1], c='red', marker='x', s=200, linewidths=3, label='Centroids')\n",
    "ax2.set_title(f'K-Means Clustering\\nSilhouette: {kmeans_silhouette:.3f}, ARI: {kmeans_ari:.3f}')\n",
    "ax2.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.3f})')\n",
    "ax2.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.3f})')\n",
    "ax2.legend()\n",
    "plt.colorbar(scatter2, ax=ax2)\n",
    "\n",
    "# K-Medoids results\n",
    "scatter3 = ax3.scatter(X_pca[:, 0], X_pca[:, 1], c=kmedoids_labels, cmap='viridis', alpha=0.7)\n",
    "# Plot medoids (transform back to PCA space)\n",
    "medoids_pca = pca.transform(X_scaled[kmedoids.medoid_indices_])\n",
    "ax3.scatter(medoids_pca[:, 0], medoids_pca[:, 1], c='red', marker='s', s=200, linewidths=2, label='Medoids')\n",
    "ax3.set_title(f'K-Medoids Clustering\\nSilhouette: {kmedoids_silhouette:.3f}, ARI: {kmedoids_ari:.3f}')\n",
    "ax3.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.3f})')\n",
    "ax3.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.3f})')\n",
    "ax3.legend()\n",
    "plt.colorbar(scatter3, ax=ax3)\n",
    "\n",
    "# Comparison plot\n",
    "x_pos = np.arange(2)\n",
    "silhouette_scores = [kmeans_silhouette, kmedoids_silhouette]\n",
    "ari_scores = [kmeans_ari, kmedoids_ari]\n",
    "\n",
    "ax4_twin = ax4.twinx()\n",
    "bars1 = ax4.bar(x_pos - 0.2, silhouette_scores, 0.4, label='Silhouette Score', alpha=0.8)\n",
    "bars2 = ax4_twin.bar(x_pos + 0.2, ari_scores, 0.4, label='Adjusted Rand Index', alpha=0.8, color='orange')\n",
    "\n",
    "ax4.set_xlabel('Clustering Algorithm')\n",
    "ax4.set_ylabel('Silhouette Score', color='blue')\n",
    "ax4_twin.set_ylabel('Adjusted Rand Index', color='orange')\n",
    "ax4.set_title('Performance Metrics Comparison')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(['K-Means', 'K-Medoids'])\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "    height1 = bar1.get_height()\n",
    "    height2 = bar2.get_height()\n",
    "    ax4.text(bar1.get_x() + bar1.get_width()/2., height1 + 0.01,\n",
    "             f'{height1:.3f}', ha='center', va='bottom')\n",
    "    ax4_twin.text(bar2.get_x() + bar2.get_width()/2., height2 + 0.01,\n",
    "                  f'{height2:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Detailed analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DETAILED ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if kmeans_silhouette > kmedoids_silhouette:\n",
    "    print(\"K-Means produced better-defined clusters (higher silhouette score)\")\n",
    "else:\n",
    "    print(\"K-Medoids produced better-defined clusters (higher silhouette score)\")\n",
    "\n",
    "if kmeans_ari > kmedoids_ari:\n",
    "    print(\"K-Means clusters align better with true classes (higher ARI)\")\n",
    "else:\n",
    "    print(\"K-Medoids clusters align better with true classes (higher ARI)\")\n",
    "\n",
    "print(\"\\nKey Differences Observed:\")\n",
    "print(\"- K-Means uses centroids (mean of cluster points)\")\n",
    "print(\"- K-Medoids uses medoids (actual data points as cluster centers)\")\n",
    "print(\"- K-Means is more sensitive to outliers\")\n",
    "print(\"- K-Medoids is more robust to outliers and noise\")\n",
    "\n",
    "print(\"\\nWhen to use each algorithm:\")\n",
    "print(\"K-Means preferable when:\")\n",
    "print(\"  - Data is spherically distributed\")\n",
    "print(\"  - Computational efficiency is important\")\n",
    "print(\"  - Data has minimal outliers\")\n",
    "\n",
    "print(\"\\nK-Medoids preferable when:\")\n",
    "print(\"  - Data contains outliers\")\n",
    "print(\"  - Need actual data points as cluster representatives\")\n",
    "print(\"  - Non-spherical cluster shapes\")\n",
    "\n",
    "# Cluster characteristics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLUSTER CHARACTERISTICS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i in range(3):\n",
    "    kmeans_size = np.sum(kmeans_labels == i)\n",
    "    kmedoids_size = np.sum(kmedoids_labels == i)\n",
    "    print(f\"Cluster {i}:\")\n",
    "    print(f\"  K-Means size: {kmeans_size}\")\n",
    "    print(f\"  K-Medoids size: {kmedoids_size}\")\n",
    "\n",
    "print(f\"\\nK-Means inertia: {kmeans.inertia_:.2f}\")\n",
    "print(f\"K-Medoids inertia: {kmedoids.inertia_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c927bb5",
   "metadata": {},
   "source": [
    " MSCS_634_Lab_3\n",
    " Roshan Gautam\n",
    " University of Cumberlands\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
